{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f0ea92-c592-46de-82aa-ff98ce7a5783",
   "metadata": {},
   "source": [
    "Notebook for https://github.com/otenim/TensorFlow-OS-ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae24ba9-d12c-4a22-be1d-620b479eb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "INFO:tensorflow:Disabling eager execution\n",
      "INFO:tensorflow:Disabling v2 tensorshape\n",
      "WARNING:tensorflow:From C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "INFO:tensorflow:Disabling resource variables\n",
      "INFO:tensorflow:Disabling tensor equality\n",
      "INFO:tensorflow:Disabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from implementations.os_elmOTENIM import OS_ELM\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb39a6d-5168-4800-b198-502ac182455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a, axis=-1).reshape(-1, 1)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a, axis=-1).reshape(-1, 1)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def metrics(true,predicted):\n",
    "    CM = confusion_matrix(predicted, true)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    a = (TP + TN) / (TP + TN + FP + FN)\n",
    "    f1 = ( 2*( p*r )) / (p + r)\n",
    "    print(\"Precision =\",p)\n",
    "    print(\"Recall =\",r)\n",
    "    print(\"Accuracy =\",a)\n",
    "    print(\"F1 =\",f1)\n",
    "    \n",
    "    sns.heatmap(CM, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ddfc905-0aab-4e95-aa3a-a0f755366aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,X,y):\n",
    "    \n",
    "    os_elm = OS_ELM(\n",
    "        n_input_nodes=n_input_nodes,\n",
    "        n_hidden_nodes=n_hidden_nodes,\n",
    "        n_output_nodes=n_output_nodes,\n",
    "        loss='mean_squared_error',\n",
    "        activation='sigmoid',\n",
    "    )\n",
    "    n_classes = n_output_nodes\n",
    "    x_train, x_test, t_train, t_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "    \n",
    "    border = int(1.2 * n_hidden_nodes)\n",
    "    x_train_init = x_train[:border]\n",
    "    x_train_seq = x_train[border:]\n",
    "    t_train_init = t_train[:border]\n",
    "    t_train_seq = t_train[border:]\n",
    "    \n",
    "    pbar = tqdm.tqdm(total=len(x_train), desc='initial training phase')\n",
    "    os_elm.init_train(x_train_init, t_train_init)\n",
    "    pbar.update(n=len(x_train_init))\n",
    "    \n",
    "    pbar.set_description('sequential training phase')\n",
    "    batch_size = 8\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        t_batch = t_train_seq[i:i+batch_size]\n",
    "        os_elm.seq_train(x_batch, t_batch)\n",
    "        pbar.update(n=len(x_batch))\n",
    "    pbar.close()\n",
    "    \n",
    "    \n",
    "    [loss, accuracy] = os_elm.evaluate(x_test, t_test, metrics=['loss', 'accuracy'])\n",
    "    print('val_loss: %f, val_accuracy: %f' % (loss, accuracy))\n",
    "    \n",
    "    y = os_elm.predict(x_test)\n",
    "    y = softmax(y)\n",
    "    \n",
    "    metrics(t_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6342da-0949-4b10-b95b-10a6b97576d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5b5d6ee-7637-4ef3-9b9b-0d9b5894bf21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable is_finished_init_train already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3557, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1750, in variable_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 74, in variable_op_v2\n    return gen_state_ops.variable_v2(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-87449f5f111a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mt_iris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_iris\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mOtenim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_hidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_output_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_iris\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_iris\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_iris\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_iris\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4ad76853d57b>\u001b[0m in \u001b[0;36mOtenim\u001b[1;34m(n_input_nodes, n_hidden_nodes, n_output_nodes, X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mOtenim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_hidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_output_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     os_elm = OS_ELM(\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mn_input_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_input_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mn_hidden_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_hidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Memoria\\MT750995Material\\OSELM\\implementations\\os_elmKERAS.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_input_nodes, n_hidden_nodes, n_output_nodes, activation, loss, name)\u001b[0m\n\u001b[0;32m     45\u001b[0m             )\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         self.__is_finished_init_train = tf.compat.v1.get_variable(\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[1;34m'is_finished_init_train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1577\u001b[0m                  \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariableSynchronization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m                  aggregation=VariableAggregation.NONE):\n\u001b[1;32m-> 1579\u001b[1;33m   return get_variable_scope().get_variable(\n\u001b[0m\u001b[0;32m   1580\u001b[0m       \u001b[0m_get_default_variable_store\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1320\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       return var_store.get_variable(\n\u001b[0m\u001b[0;32m   1323\u001b[0m           \u001b[0mfull_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    576\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m       return _true_getter(\n\u001b[0m\u001b[0;32m    579\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \"name was already created with partitioning?\" % name)\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m       return self._get_single_variable(\n\u001b[0m\u001b[0;32m    532\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;31m# default case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0m\u001b[0;32m    895\u001b[0m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0;32m    896\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable is_finished_init_train already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3557, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1750, in variable_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 74, in variable_op_v2\n    return gen_state_ops.variable_v2(\n"
     ]
    }
   ],
   "source": [
    "#IRIS DATASET\n",
    "from sklearn import datasets\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "n_input_nodes = 4\n",
    "n_hidden_nodes = 16\n",
    "n_output_nodes = 3\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x_iris, t_iris = iris.data, iris.target\n",
    "\n",
    "# normalize each column value\n",
    "mean = np.mean(x_iris, axis=0)\n",
    "std = np.std(x_iris, axis=0)\n",
    "x_iris = (x_iris - mean) / std\n",
    "\n",
    "# convert label data into one-hot-vector format data.\n",
    "t_iris = to_categorical(t_iris, num_classes=3)\n",
    "\n",
    "Otenim(n_input_nodes,n_hidden_nodes,n_output_nodes,x_iris,t_iris)\n",
    "\n",
    "print(x_iris,t_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e528bcf0-8f4a-45ad-85d6-def56d7260d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable is_finished_init_train already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3557, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1750, in variable_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 74, in variable_op_v2\n    return gen_state_ops.variable_v2(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ed3b9868ad8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mn_output_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m os_elm = OS_ELM(\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# the number of input nodes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mn_input_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_input_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Memoria\\MT750995Material\\OSELM\\implementations\\os_elmOTENIM.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_input_nodes, n_hidden_nodes, n_output_nodes, activation, loss, name)\u001b[0m\n\u001b[0;32m     45\u001b[0m             )\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         self.__is_finished_init_train = tf.get_variable(\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[1;34m'is_finished_init_train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1577\u001b[0m                  \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariableSynchronization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m                  aggregation=VariableAggregation.NONE):\n\u001b[1;32m-> 1579\u001b[1;33m   return get_variable_scope().get_variable(\n\u001b[0m\u001b[0;32m   1580\u001b[0m       \u001b[0m_get_default_variable_store\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1320\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       return var_store.get_variable(\n\u001b[0m\u001b[0;32m   1323\u001b[0m           \u001b[0mfull_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    576\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m       return _true_getter(\n\u001b[0m\u001b[0;32m    579\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \"name was already created with partitioning?\" % name)\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m       return self._get_single_variable(\n\u001b[0m\u001b[0;32m    532\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;31m# default case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0m\u001b[0;32m    895\u001b[0m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0;32m    896\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable is_finished_init_train already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3557, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1750, in variable_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\clroc\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 74, in variable_op_v2\n    return gen_state_ops.variable_v2(\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# Instantiate os-elm\n",
    "# ===========================================\n",
    "from sklearn import datasets\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "n_input_nodes = 4\n",
    "n_hidden_nodes = 16\n",
    "n_output_nodes = 3\n",
    "\n",
    "os_elm = OS_ELM(\n",
    "    # the number of input nodes.\n",
    "    n_input_nodes=n_input_nodes,\n",
    "    # the number of hidden nodes.\n",
    "    n_hidden_nodes=n_hidden_nodes,\n",
    "    # the number of output nodes.\n",
    "    n_output_nodes=n_output_nodes,\n",
    "    # loss function.\n",
    "    # the default value is 'mean_squared_error'.\n",
    "    # for the other functions, we support\n",
    "    # 'mean_absolute_error', 'categorical_crossentropy', and 'binary_crossentropy'.\n",
    "    loss='mean_squared_error',\n",
    "    # activation function applied to the hidden nodes.\n",
    "    # the default value is 'sigmoid'.\n",
    "    # for the other functions, we support 'linear' and 'tanh'.\n",
    "    # NOTE: OS-ELM can apply an activation function only to the hidden nodes.\n",
    "    activation='sigmoid',\n",
    ")\n",
    "\n",
    "# ===========================================\n",
    "# Prepare dataset\n",
    "# ===========================================\n",
    "n_classes = n_output_nodes\n",
    "\n",
    "# load Iris\n",
    "iris = datasets.load_iris()\n",
    "x_iris, t_iris = iris.data, iris.target\n",
    "\n",
    "# normalize each column value\n",
    "mean = np.mean(x_iris, axis=0)\n",
    "std = np.std(x_iris, axis=0)\n",
    "x_iris = (x_iris - mean) / std\n",
    "\n",
    "# convert label data into one-hot-vector format data.\n",
    "t_iris = to_categorical(t_iris, num_classes=n_classes)\n",
    "\n",
    "# shuffle dataset\n",
    "perm = np.random.permutation(len(x_iris))\n",
    "x_iris = x_iris[perm]\n",
    "t_iris = t_iris[perm]\n",
    "\n",
    "# divide dataset for training and testing\n",
    "border = int(len(x_iris) * 0.8)\n",
    "x_train, x_test = x_iris[:border], x_iris[border:]\n",
    "t_train, t_test = t_iris[:border], t_iris[border:]\n",
    "\n",
    "# divide the training dataset into two datasets:\n",
    "# (1) for the initial training phase\n",
    "# (2) for the sequential training phase\n",
    "# NOTE: the number of training samples for the initial training phase\n",
    "# must be much greater than the number of the model's hidden nodes.\n",
    "# here, we assign int(1.2 * n_hidden_nodes) training samples\n",
    "# for the initial training phase.\n",
    "border = int(1.2 * n_hidden_nodes)\n",
    "x_train_init = x_train[:border]\n",
    "x_train_seq = x_train[border:]\n",
    "t_train_init = t_train[:border]\n",
    "t_train_seq = t_train[border:]\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# Training\n",
    "# ===========================================\n",
    "# the initial training phase\n",
    "pbar = tqdm.tqdm(total=len(x_train), desc='initial training phase')\n",
    "os_elm.init_train(x_train_init, t_train_init)\n",
    "pbar.update(n=len(x_train_init))\n",
    "\n",
    "# the sequential training phase\n",
    "pbar.set_description('sequential training phase')\n",
    "batch_size = 8\n",
    "for i in range(0, len(x_train_seq), batch_size):\n",
    "    x_batch = x_train_seq[i:i+batch_size]\n",
    "    t_batch = t_train_seq[i:i+batch_size]\n",
    "    os_elm.seq_train(x_batch, t_batch)\n",
    "    pbar.update(n=len(x_batch))\n",
    "pbar.close()\n",
    "\n",
    "# ===========================================\n",
    "# Prediction\n",
    "# ===========================================\n",
    "# sample 10 validation samples from x_test\n",
    "n = 10\n",
    "x = x_test[:n]\n",
    "t = t_test[:n]\n",
    "\n",
    "# 'predict' method returns raw values of output nodes.\n",
    "y = os_elm.predict(x)\n",
    "# apply softmax function to the output values.\n",
    "y = softmax(y)\n",
    "\n",
    "# check the answers.\n",
    "for i in range(n):\n",
    "    max_ind = np.argmax(y[i])\n",
    "    print('========== sample index %d ==========' % i)\n",
    "    print('estimated answer: class %d' % max_ind)\n",
    "    print('estimated probability: %.3f' % y[i,max_ind])\n",
    "    print('true answer: class %d' % np.argmax(t[i]))\n",
    "\n",
    "# ===========================================\n",
    "# Evaluation\n",
    "# ===========================================\n",
    "# we currently support 'loss' and 'accuracy' for 'metrics'.\n",
    "# NOTE: 'accuracy' is valid only if the model assumes\n",
    "# to deal with a classification problem, while 'loss' is always valid.\n",
    "# loss = os_elm.evaluate(x_test, t_test, metrics=['loss']\n",
    "[loss, accuracy] = os_elm.evaluate(x_test, t_test, metrics=['loss', 'accuracy'])\n",
    "print('val_loss: %f, val_accuracy: %f' % (loss, accuracy))\n",
    "\n",
    "# ===========================================\n",
    "# Save model\n",
    "# ===========================================\n",
    "print('saving model parameters...')\n",
    "os_elm.save('./checkpoint/model.ckpt')\n",
    "\n",
    "# initialize weights of os_elm\n",
    "os_elm.initialize_variables()\n",
    "\n",
    "# ===========================================\n",
    "# Load model\n",
    "# ===========================================\n",
    "# If you want to load weights to a model,\n",
    "# the architecture of the model must be exactly the same\n",
    "# as the one when the weights were saved.\n",
    "print('restoring model parameters...')\n",
    "os_elm.restore('./checkpoint/model.ckpt')\n",
    "\n",
    "# ===========================================\n",
    "# ReEvaluation\n",
    "# ===========================================\n",
    "# loss = os_elm.evaluate(x_test, t_test, metrics=['loss']\n",
    "[loss, accuracy] = os_elm.evaluate(x_test, t_test, metrics=['loss', 'accuracy'])\n",
    "print('val_loss: %f, val_accuracy: %f' % (loss, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
